# Kafka Hands-in

>Kafka On Kubernetes





# 1. Strimzi



## 1.1 Strimzi 란 ?



Strimzi는 Kubernetes 클러스터에서 Apache Kafka를 실행하는 프로세스를 단순화시키는 오픈소스 툴이다.

- Strimzi는 Kubernetes에서 Kafka를 실행하기 위한 컨테이너 이미지 및 Operator를 제공함

- Operator 는 Kubernetes 에서 운영작업을 단순화 하기 위해 제공되는 CRD(Custom Resource Definition) 의 운영체
- Strimzi Operator 는 Kubernetes 기능을 확장하여 Kafka 배포와 관련된 일반적이고 복잡한 작업을 자동화



## 1.2 Strimzi Operator

Strimzi는 Kubernetes 클러스터 내에서 실행되는 Kafka 클러스터를 관리하기 위한 운영자를 제공한다.

- Cluster Operator

  Apache Kafka Cluster, Kafka Connect, Kafka MirrorMaker, Kafka Bridge, Kafka Exporter, Cruise Control 및 Entity Operator 배포 및 관리

- Topic  Operator

  Kafka Topic을 관리합니다.

- User Operator

  Kafka User 관리



![Operators within the Strimzi architecture](2.kafka-hands-in.assets/operators.png)





# 2. Strimzi Cluster Operator Install

Strimzi Cluster Operator 를 install 한다.



## 2.1 namespace 생성

strimzi operator 와 kafka cluster 를 kafka namespace 에 설치해야 한다.  worker node 를 준비한후 kafka namespace 를 생성하자.

```sh
# namespace 생성
$ kubectl create ns kafka

# 확인
$ kubectl get ns

NAME              STATUS   AGE
default           Active   4h42m
kafka             Active   11s
kube-node-lease   Active   4h42m
kube-public       Active   4h42m
kube-system       Active   4h42m


# alias 설정
$ alias kkf='kubectl -n kafka'
```





## 2.2 Strmzi download

사전에 download 받아 놓은 실습자료에 설치 파일이 존재한다.

참고로 strimzi site 에서 최신버젼을 다운로드 받을 수 있다.

- 링크: https://strimzi.io/downloads/





## 2.3 Single name 모드 namespace 설정

- single name 모드로 설치진행
  - strimzi operator 는 다양한 namespace 에서 kafka cluster 를 쉽게 생성할 수 있는 구조로 운영이 가능하다.  이때 STRIMZI_NAMESPACE 를 설정하여 특정 namespace 만으로 cluster 를 제한 할 수 있다.  ICIS-TR SA의 경우는 kafka-system 라는 namespace 에서만  kafka cluster 를 구성할 수 있도록 설정한다. 그러므로 아래 중 Single namespace 설정에 해당한다.

```sh
$ cd ~/githubrepo/ktds-edu2

$ sed -i 's/namespace: .*/namespace: kafka/' kafka/strimzi/install/cluster-operator/*RoleBinding*.yaml
```





## 2.4 Operator Deploy

- kafka namespace 를 watch 할 수 있는 권한 부여

```sh
$ cd ~/githubrepo/ktds-edu2

# kafka namespace 를 watch 할 수 있는 권한 부여
# 1) operator 권한부여
$ kubectl -n kafka create -f ./kafka/strimzi/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml

# 2) entity-operator 권한부여
$ kubectl -n kafka create -f ./kafka/strimzi/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml

# 3) Deploy the CRDs
$ kubectl -n kafka create -f ./kafka/strimzi/install/cluster-operator/



# operator 설치 확인
$ kubectl -n kafka get pod
NAME                                        READY   STATUS    RESTARTS   AGE
strimzi-cluster-operator-86864b86d5-8rlfx   1/1     Running   0          2m34s


# operator pod log 확인
$ kubectl -n kafka logs -f strimzi-cluster-operator-86864b86d5-8rlfx

2022-07-02 08:09:51 INFO  ClusterOperator:79 - Creating ClusterOperator for namespace kafka
2022-07-02 08:09:51 INFO  ClusterOperator:94 - Starting ClusterOperator for namespace kafka



```



# 3. Kafka Cluster 생성



## 3.1 Kafka Cluster 생성

인증 작업



### (1) Kafka cluster 생성(인증)

```sh
$ cd ~/githubrepo/ktds-edu2

$ cat ./kafka/strimzi/kafka/12.kafka-ephemeral-auth.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
spec:
  kafka:
    version: 3.2.0
    replicas: 3
    authorization:
      type: simple
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
        authentication:
          type: scram-sha-512
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: "3.2"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

# kafka Cluster 생성
$ kubectl -n kafka apply -f ./kafka/strimzi/kafka/12.kafka-ephemeral-auth.yaml

```

- 인증메커니즘

  - SASL 은 인증 및 보안 서비스를 제공하는 프레임워크이다.
  - 위 yaml 파일의 인증방식은 scram-sha-512  방식인데 이는 SASL 이 지원하는 메커니즘 중 하나이며 Broker 를 SASL 구성로 구성한다.



### (2) Kafka Cluster 확인

```sh

$ kkf get pod -w

$ kkf get pod
NAME                                         READY   STATUS    RESTARTS   AGE
my-cluster-entity-operator-7cfdb67c4-d4qc7   3/3     Running   0          3m24s
my-cluster-kafka-0                           1/1     Running   0          4m3s
my-cluster-kafka-1                           1/1     Running   0          4m3s
my-cluster-kafka-2                           1/1     Running   0          4m3s
my-cluster-zookeeper-0                       1/1     Running   0          4m28s
my-cluster-zookeeper-1                       1/1     Running   0          4m28s
my-cluster-zookeeper-2                       1/1     Running   0          4m28s
strimzi-cluster-operator-86864b86d5-8rlfx    1/1     Running   0          5h24m

# kafka broker 3개와  zookeeper 3개 실행된것을 확인 할 수 있다.




# Kafka Cluster 확인
$ kkf get kafka
NAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS
my-cluster   3                        3                     True

# kafka Cluster 의 ready 상태가 True 인것을 확인하자.

```







### (3) [참고]Kafka cluster 생성(No 인증)

아래는 인증없이 접근 가능한 kafka cluster 를 생성하는 yaml 이므로 참고만 하자.

```sh
$ cd ~/githubrepo/ktds-edu2

$ cat ./kafka/strimzi/kafka/11.kafka-ephemeral-no-auth.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
spec:
  kafka:
    version: 3.2.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: "3.2"
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {} 


$ kubectl -n kafka apply -f  ./strimzi/kafka/11.kafka-ephemeral-no-auth.yaml

```







## 3.2  KafkaUser

- kafka cluster 생성시 scram-sha-512 type 의 authentication 를 추가했다면 반드시 KafkaUser 가 존재해야 한다.

- KafkaUser 를 생성하면 secret 에 Opaque 가 생성되며 향후 인증 password 로 사용된다.
- 어떤 topic 에 어떻게 접근할지 에 대한 ACL 기능을 추가할 수 있다.



### (1) User 정책

아래와 같이 ACL (Access Control List) 정책을 지정할 수 있다.

- sample user 별 설명

```
ㅇ my-user
my 로 시작하는 모든 topic을 처리할 수 있음
my 로 시작하는 모든 group을 Consume 가능

ㅇ order-user
order로 시작하는 모든 topic을 처리할 수 있음
order로 시작하는 모든 group을 Consume 가능

ㅇ order-user-readonly
order로 시작하는 모든 topic을 읽을 수 있음
order로 시작하는 모든 group을 Consume 가능
```



### (2) KafkaUser생성

```sh
$ cd ~/githubrepo/ktds-edu2

$ cat ./kafka/strimzi/user/11.kafka-user.yaml
---
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: arsenal-cluster
  namespace: kafka
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - operation: All
        resource:
          type: topic
          name: my
          patternType: prefix
      - operation: All
        resource:
          name: my
          patternType: prefix
          type: group
      - operation: All
        resource:
          type: topic
          name: edu
          patternType: prefix
      - operation: All
        resource:
          name: edu
          patternType: prefix
          type: group
---


# KafkaUser 생성 명령 실행
$ kubectl -n kafka apply -f ./kafka/strimzi/user/11.kafka-user.yaml

# kafkauser 확인
$ kubectl -n kafka get kafkauser
NAME      CLUSTER      AUTHENTICATION   AUTHORIZATION   READY
my-user   my-cluster   scram-sha-512    simple          True

# Ready 상태가 True인것을 확인하자.
```

- ACL 권한설명

  - my~  또는 edu 로 시작하는 topic 을 모두 처리가능
  - ex) my-board-create,  my-board-update,  edu-topic

  

  

### (3) password 확인

```sh

$ kubectl -n kafka get secret my-user
NAME      TYPE     DATA   AGE
my-user   Opaque   2      28s


$ kubectl -n kafka get secret my-user -o jsonpath='{.data.password}' | base64 -d
iZ1cexpFxoy1

# user/pass 
## 강사님 기준 : my-user / PkcAIUblNHFg 
## 수강생 기준 : my-user /               <-- 여기에 Password 를 기록하세요.
  
  
```







## 3.3 KafkaTopic



### (1) Topic 정책 

앞서 KafkaUser 의 ACL 기능을 이용해서 kafka topic 을 제어하는 방법을 확인했다.  topiic 명칭을 어떻게 정하는지에 대해서 다양한 시나리오를 생각해 볼 수 있다. 아래 특정 프로젝트의 topic name 정책을 살펴보자.

- topic 정책

```
[Part명]-[서비스명]-[서브도메인]-[사용자정의]
```



#### [참고] ICIS-TR Topic Name 정책

```
order-intl-board-create
order-intl-board-update
order-intl-board-delete

bill-intl-board-create
bill-intl-board-update
bill-intl-board-delete

rater-intl-board-create
rater-intl-board-update
rater-intl-board-delete
```





### (2) KafkaTopic 생성

```sh
$ cd ~/githubrepo/ktds-edu2

$ cat ./kafka/strimzi/topic/11.kafka-topic.yaml
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
  namespace: kafka
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 7200000      # 2 hour
    #retention.ms: 86400000      # 24 hours
    segment.bytes: 1073741824   # 1GB


# topic 생성 명령 실행
$ kubectl -n kafka apply -f ./kafka/strimzi/topic/11.kafka-topic.yaml


# topic 생성 확인
$ kubectl -n kafka get kafkatopic my-topic
NAME       CLUSTER      PARTITIONS   REPLICATION FACTOR   READY
my-topic   my-cluster   3            3                    True

```



### (3) Topic  상세 확인

```sh

$ kubectl -n kafka get kafkatopic my-topic -o yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"kafka.strimzi.io/v1beta2","kind":"KafkaTopic","metadata":{"annotations":{},"labels":{"strimzi.io/cluster":"my-cluster"},"name":"my-topic","namespace":"kafka"},"spec":{"config":{"retention.ms":86400000,"segment.bytes":1073741824},"partitions":3,"replicas":3}}
  creationTimestamp: "2022-06-30T12:34:43Z"
  generation: 1
  labels:
    strimzi.io/cluster: my-cluster
  name: my-topic
  namespace: kafka
  resourceVersion: "7118"
  uid: 53b4001d-1b54-48c9-b749-997a5beb8dd4
spec:
  config:
    retention.ms: 86400000
    segment.bytes: 1073741824
  partitions: 3
  replicas: 3
status:
  conditions:
  - lastTransitionTime: "2022-06-30T12:34:44.290021Z"
    status: "True"
    type: Ready
  observedGeneration: 1
  topicName: my-topic

```

- status 에서 true, ready 임을 확인하자.





# 4. Accessing Kafka

- Kafka 의 주요기능중 하나는 확장성이다.  즉, 데이터를 분할하고 여러 브로커에 파티션을 분산하여 관리한다. 

- 그러므로 이러한 분상환경은 Client 가 Broker 에 연결하는 방식에도 큰 영향을 미친다. 
- kafka 는 Kubernetes 플랫폼 내에서 실행중이므로 Kubernetes 플랫폼 내부/외부에서 접근한할때 각각 방식이 다르다. 
- 이런 작동원리에 대해서 살펴보자.



## 4.1 Broker 접근 방식의 이해



### (1) Client 와 Broker Connect

- 특정 파티션에 지정된 클라이언트는 해당 파티션을 호스팅하는 리더 브로커에 직접 연결함

- 그러므로 브로커간 데이터전달 불필요하며 이러한 방식은 클러스터내 트래픽의 양을 줄이는데 도움이 됨

![파티션에 연결하는 클라이언트](2.kafka-hands-in.assets/2019-04-17-connecting-to-leader.png)



클라이언트는 어떻게 해당 브로커의 위치를 알 수 있을까?



### (2) kafka discovery protocol

- Kafka에는 자체 discovery protocol 이 있음

- Kafka 클라이언트가 Kafka 클러스터에 연결할 때 먼저 클러스터의 구성원인 브로커에 연결하고 하나 이상의 주제에 대한 메타데이터 를 요청함
- 메타데이터에는 Topic, 해당 Partition 및 이러한 Partition 을 호스팅하는 브로커에 대한 정보가 포함됨 
- 모든 브로커는 Zookeeper를 통해 모두 동기화되기 때문에 전체 클러스터에 대해 이 데이터를 가지고 있음
- 따라서 클라이언트가 처음으로 연결된 브로커는 중요하지 않으며 모든 브로커가 동일한 응답을 제공함

![Kafka 클라이언트와 Kafka 클러스터 간의 연결 흐름](2.kafka-hands-in.assets/2019-04-17-connection-flow.png)

- 클라이언트는 *메타데이터* 를 사용 하여 주어진 파티션에 쓰거나 읽으려고 할 때 연결할 위치를 파악함

- *메타데이터* 에 사용된 브로커 주소 는 브로커가 실행되는 시스템의 호스트 이름을 기반으로 브로커 자체에서 생성됨
- 또는 `advertised.listeners` 옵션을 사용하여 사용자가 구성할 수 있음





### (3) Internal Access 과 External Access

DEV환경과 PRD 환경을 각각 생각해 보자.

PRD 환경의 경우 Kubernetes Cluster내에 설치된 Kafka가 설치되어 있고 연결을 원하는 App이 해당 클러스터 내에 배포된 상태에서 Kafka를 접속한다.

그러므로 Kakfa 를 접속시 Cluster 내부 주소체계를 사용한다.  (Internal Access)

하지만 DEV환경의 경우 개발자PC와 같이 Kubernetes Cluster 외부에서 접근해야 하므로 별도의 주소체계가 있어야 한다. (External Access)

이러한 부분의 차이가 있음을 이해하자.



### (4) 클러스터 내부에서 연결

- Kafka 클러스터와 동일한 Kubernetes 클러스터 내에서 실행되는 클라이언트는 Kubernetes `service` 를 이용해서 접근함
- Strimzi는 Kafka 브로커를 StatefulSet로 실행함
- 그러므로 `Kubernetes headless service` 를 사용하여 각 pod별 고유한  DNS 이름을 가질 수 있음
- Strimzi는 이러한 DNS 이름을 `advertised.listeners`로 사용하고 있음





![동일한 Kubernetes 클러스터 내에서 Kafka에 액세스](2.kafka-hands-in.assets/2019-04-17-inside-kubernetes.png)



- 초기 연결은 *메타데이터* 를 가져오기 위해 일반 Kubernetes service 를 사용하여 수행됩니다 .
- 후속 연결은 다른 headless Kubernetes service 에서 Pod에 제공한 DNS 이름을 사용하여 열립니다. 









## 4.2 Internal Access



### (1) Kafka Cluster Service 확인



```sh
$ kubectl -n kafka get svc
NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGE
my-cluster-kafka-bootstrap    ClusterIP   10.105.0.19     <none>        9091/TCP,9092/TCP,9093/TCP            75m
my-cluster-kafka-brokers      ClusterIP   None            <none>        9090/TCP,9091/TCP,9092/TCP,9093/TCP   75m
my-cluster-zookeeper-client   ClusterIP   10.105.55.137   <none>        2181/TCP                              75m
my-cluster-zookeeper-nodes    ClusterIP   None            <none>        2181/TCP,2888/TCP,3888/TCP            75m


$ kubectl -n kafka get pod
NAME                                         READY   STATUS    RESTARTS   AGE
my-cluster-entity-operator-7cfdb67c4-d4qc7   3/3     Running   0          76m
my-cluster-kafka-0                           1/1     Running   0          76m
my-cluster-kafka-1                           1/1     Running   0          76m
my-cluster-kafka-2                           1/1     Running   0          76m
my-cluster-zookeeper-0                       1/1     Running   0          77m
my-cluster-zookeeper-1                       1/1     Running   0          77m
my-cluster-zookeeper-2                       1/1     Running   0          77m
strimzi-cluster-operator-86864b86d5-8rlfx    1/1     Running   0          6h37m

```

- my-cluster-kafka-bootstrap 이 일반 kubernetes service 이며 POD 로 트래픽을 RR 방식으로 연결한다.
- my-cluster-kafka-brokers 는 ip 가 없는 headless service 이다. 그러므로 pod 명을 붙여서 DNS 로 사용된다.
  - headless service 사용예시
    - my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc
    - my-cluster-kafka-1.my-cluster-kafka-brokers.kafka.svc
    - my-cluster-kafka-2.my-cluster-kafka-brokers.kafka.svc

- 우리는 Cluster 내에서  my-cluster-kafka-bootstrap:9092 로 접근을 시도할 것이다.





### (2) kafkacat 로 확인

Kubernetes Cluster 내에서 kafka 접근 가능여부를 확인하기 위해 kafka Client 용 app 인 kafkacat 을 설치하자.



#### kafkacat 설치

```sh
# kafka cat 설치
$ kubectl -n kafka create deploy kafkacat \
    --image=confluentinc/cp-kafkacat:latest \
    -- sleep 365d

# 설치진행 확인
$ kubectl -n kafka get pod
NAME                                         READY   STATUS              RESTARTS   AGE
kafkacat-7648db7f48-wg4hn                    0/1     ContainerCreating   0          4s


## READY 상태가 1/1 로 변할때까지 대기...


# pod 내부로 진입( bash 명령 수행)
$ kubectl -n kafka exec -it deploy/kafkacat -- bash
[appuser@kafkacat-7648db7f48-wg4hn ~]$



```



#### ※ 참고
windows 환경의 gitbash 를 이용해 pod 내부명령을 수행한다면 prompt 가 보이지 않을수도 있다.

이런경우 windows 에서 linux 체제와 호환이 되지 않아서 발생하는 이슈이다.

아래와 같이 winpty 를 붙인다면 prompt 가 보이니 참고하자.

```sh

# pod 내부명령 수행
$ winpty kubectl -n kafka exec -it deploy/kafkacat -- bash

```





#### pub/sub test

id/pass 가 필요

```sh
$ kubectl -n kafka exec -it deploy/kafkacat -- bash

export BROKERS=my-cluster-kafka-bootstrap:9092
export KAFKAUSER=my-user
export PASSWORD=KV9tDU0AY4Wu        ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
export TOPIC=my-topic
 
 
## topic 리스트
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD -L

Metadata for all topics (from broker -1: sasl_plaintext://my-cluster-kafka-bootstrap:9092/bootstrap):
 3 brokers:
  broker 0 at my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9092
  broker 2 at my-cluster-kafka-2.my-cluster-kafka-brokers.kafka.svc:9092
  broker 1 at my-cluster-kafka-1.my-cluster-kafka-brokers.kafka.svc:9092 (controller)
 1 topics:
  topic "my-topic" with 3 partitions:
    partition 0, leader 1, replicas: 1, isrs: 1
    partition 1, leader 0, replicas: 0, isrs: 0
    partition 2, leader 2, replicas: 2, isrs: 2

## 위 내용중 3개의 brokers 주소를 잘 이해하자.
## 위주소는 headless service 이용한 pod dns 이다.


## consumer
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C -o -5


## terminal 을 한개 더 실행하여 위 환경변수 인식후 아래 producer 를 실행하자.
## producer
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1 

# 임의의 text 실행
```



- Consumer 결과확인

```
% Reached end of topic my-topic [2] at offset 0
% Reached end of topic my-topic [0] at offset 0
% Reached end of topic my-topic [1] at offset 0

asdf
% Reached end of topic my-topic [2] at offset 1
asdf
% Reached end of topic my-topic [2] at offset 2
asdf
asd
% Reached end of topic my-topic [1] at offset 2
fsad
% Reached end of topic my-topic [2] at offset 3
f
% Reached end of topic my-topic [2] at offset 4
sdf
% Reached end of topic my-topic [1] at offset 3
asdfasd
% Reached end of topic my-topic [0] at offset 1
fas
% Reached end of topic my-topic [0] at offset 2
fsda
% Reached end of topic my-topic [0] at offset 3
fsa
% Reached end of topic my-topic [1] at offset 4

```

- offset 값이 partition 단위로 증가됨을 할 수 있다.





#### [참고] kafkacat 추가명령

```sh

## consumer group
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C \
  -X group.id=my-board-group




## consumer group
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C \
  -X group.id=order-intl-board-group -o -5



## producer : 입력모드
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1
 


## 대량 발송 모드
$ cat > msg.txt
---
{"eventName":"a","num":1,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }
---

## producer : file mode
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P ./msg.txt


## producer : while
while true; do kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P ./msg.txt; done;

```









## 4.3 External Access(Node Port)

참고: https://strimzi.io/blog/2019/04/17/accessing-kafka-part-1/

- Strimzi 는 외부에서 접근가능하도록  다양한 기능을 제공함

- Strimzi 가 제공하는 외부 접근방식
  - Node port
  - Ingress
  - Openshift Route
  - Load Balancer




그중 Node Port 접근 방식을 알아보자.



### (1) Node Port

#### Node IP 확인

- node port 를 인식할 수 있는 본인 PC 의 IP를 확인하자.
- 이 IP 는 아래 Node Port 등록시 nip host 에 사용된다.
- 참고로 본인  IP 는 아래와 같이 command 창에서  `ipconfig` 명령으로 확인할 수 있다. (WSL 이 아닌 Windows Command 임을 유의하자)

```sh
$ ipconfig

Windows IP 구성

무선 LAN 어댑터 로컬 영역 연결* 1:

미디어 상태 . . . . . . . . : 미디어 연결 끊김
연결별 DNS 접미사. . . . :

무선 LAN 어댑터 로컬 영역 연결* 10:

미디어 상태 . . . . . . . . : 미디어 연결 끊김
연결별 DNS 접미사. . . . :

이더넷 어댑터 VMware Network Adapter VMnet1:

연결별 DNS 접미사. . . . :
링크-로컬 IPv6 주소 . . . . : fe80::b43c:3b41:b773:48da%9
IPv4 주소 . . . . . . . . . : 192.168.31.1                   <=============  해당 IP 를 추출한다.
서브넷 마스크 . . . . . . . : 255.255.255.0
기본 게이트웨이 . . . . . . :

이더넷 어댑터 VMware Network Adapter VMnet8:

연결별 DNS 접미사. . . . :
링크-로컬 IPv6 주소 . . . . : fe80::905c:f7ec:a1e4:7ca6%12
IPv4 주소 . . . . . . . . . : 192.168.239.1
서브넷 마스크 . . . . . . . : 255.255.255.0
...
```

  위 정보는 개인마다 틀린점을 유의하자.





#### NodePort Listener 등록

- Kafka Cluster 를 수정모드로 변경하여 node port  listener 를 삽입하자.
- node Port 를 직접 명시할 수 있다.
- AdvertisedHost 필드에는 DNS 이름이나 IP 주소를 표기할 수 있다.

```sh
$ kubectl -n kafka edit kafka my-cluster

apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
  ...
spec:
  ...
    listeners:
    - authentication:
        type: scram-sha-512
      name: plain
      port: 9092
      tls: false
      type: internal
    - name: tls
      port: 9093
      tls: true
      type: internal
    
    ## nodeport type 등록 - 아래내용을 삽입 하자.
    - name: external
      port: 9094
      type: nodeport
      tls: false
      authentication:
        type: scram-sha-512
      configuration:
        bootstrap:
          nodePort: 32100
        brokers:
        - broker: 0
          advertisedHost: my-cluster.kafka.localhost.192.168.31.1.nip.io    # 각자의 Node IP로 변경
          nodePort: 32000
        - broker: 1
          advertisedHost: my-cluster.kafka.localhost.192.168.31.1.nip.io    # 각자의 Node IP로 변경
          nodePort: 32001
        - broker: 2
          advertisedHost: my-cluster.kafka.localhost.192.168.31.1.nip.io    # 각자의 Node IP로 변경
          nodePort: 32002

...
---


```






#### Kafka Cluster 확인

```sh

# 확인
$ kubectl -n kafka get kafka my-cluster
NAME         DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   WARNINGS
my-cluster   3                        3                     True


$ kubectl -n kafka get kafka my-cluster -o yaml
...
status:
...
  - addresses:
    - host: my-cluster.kafka.localhost.192.168.31.1.nip.io
      port: 32100
    bootstrapServers: my-cluster.kafka.localhost.192.168.31.1.nip.io:32100
    name: external
    type: external
---

## name: external 이 표기되어야 정상 반영 된 것이다.


$ kubectl -n kafka get svc
NAME                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGE
my-cluster-kafka-0                    NodePort    10.97.170.245   <none>        9094:32000/TCP                        40s
my-cluster-kafka-1                    NodePort    10.100.53.205   <none>        9094:32001/TCP                        40s
my-cluster-kafka-2                    NodePort    10.98.147.138   <none>        9094:32002/TCP                        40s
my-cluster-kafka-bootstrap            ClusterIP   10.105.0.19     <none>        9091/TCP,9092/TCP,9093/TCP            99m
my-cluster-kafka-brokers              ClusterIP   None            <none>        9090/TCP,9091/TCP,9092/TCP,9093/TCP   99m
my-cluster-kafka-external-bootstrap   NodePort    10.111.171.14   <none>        9094:32100/TCP                        40s
my-cluster-zookeeper-client           ClusterIP   10.105.55.137   <none>        2181/TCP                              99m
my-cluster-zookeeper-nodes            ClusterIP   None            <none>        2181/TCP,2888/TCP,3888/TCP            99m


```

- 외부에서 접근시 아래 주소로 cluster내부에 있는 kafka 에 접근 할 수 있다.

  ```
  bootstrap  : my-cluster.kafka.localhost.192.168.31.1.nip.io:32100
  broker0    : my-cluster.kafka.localhost.192.168.31.1.nip.io:32000
  broker1    : my-cluster.kafka.localhost.192.168.31.1.nip.io:32001
  broker2    : my-cluster.kafka.localhost.192.168.31.1.nip.io:32002
  ```

  



### (2) kafkacat 로 확인

Local PC(Cluster 외부) 에서  kafka 접근 가능여부를 확인하기 위해 kafkacat 을 docker 로 PC 에 설치하자.

#### docker run

kafkacat 을 docker 로 설치한다.

※  참고로 지금까지 잘 따라 왔다면 아마도 wsl 에서도 docker 접근이 가능한 환경일 것이다. 그러므로 동일한 terminal 에서 수행하면 된다.

```sh
# 실행
$ docker run --name kafkacat -d --user root confluentinc/cp-kafkacat:latest sleep 365d


# 확인
$ docker ps -a
CONTAINER ID   IMAGE                             COMMAND                  CREATED          STATUS                      PORTS     NAMES
3a0ae7a699ad   confluentinc/cp-kafkacat:latest   "sleep 365d"             2 weeks ago      Up 2 seconds                          kafkacat


# docker 내부로 진입( bash 명령 수행)
$  docker exec -it kafkacat bash
[root@3a0ae7a699ad appuser]#

```



#### pub/sub 확인

password  와 주소를 확인한 후 변경하자.

```sh
$ docker exec -it kafkacat bash

export BROKERS=my-cluster.kafka.localhost.192.168.31.1.nip.io:32100
export KAFKAUSER=my-user
export PASSWORD=iZ1cexpFxoy1        ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 
export TOPIC=my-topic
export GROUP=my-topic-group


## topic 리스트
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD -L
  
  
Metadata for all topics (from broker -1: sasl_plaintext://my-cluster.kafka.localhost.192.168.31.1.nip.io:32100/bootstrap):
 3 brokers:
  broker 0 at my-cluster.kafka.localhost.192.168.31.1.nip.io:32000
  broker 2 at my-cluster.kafka.localhost.192.168.31.1.nip.io:32002 (controller)
  broker 1 at my-cluster.kafka.localhost.192.168.31.1.nip.io:32001
 1 topics:
  topic "my-topic" with 3 partitions:
    partition 0, leader 2, replicas: 2,1,0, isrs: 1,2,0
    partition 1, leader 1, replicas: 1,0,2, isrs: 1,2,0
    partition 2, leader 0, replicas: 0,2,1, isrs: 1,2,0

# 3개의 brokers 를 확인하자.
# Internal 에서 확인했을때와 주소가 다른 것을 확인할 수 있다.
# local PC 에서 접근가능한 3개의 nodeport 주소가 kafka discovery 에 의해 반환되었다.
# kafka discovery protocol 임을 이해하자.


## consumer
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -C -o -5



## terminal 을 한개 더 실행하여 위 환경변수 인식후 아래 producer 를 실행하자.
## producer : 입력모드
kafkacat -b $BROKERS \
  -X security.protocol=SASL_PLAINTEXT \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$KAFKAUSER \
  -X sasl.password=$PASSWORD \
  -t $TOPIC -P -X acks=1
  

```







# 5. python

python 을 활용하여 kafka 연결을 시도해 보자. 



## 5.1 Internal Access



### (1) 준비

#### Internal access 를 위한 Cluter python 실행

```sh
## cluster 에서 실행
# python deploy
$ kubectl -n kafka create deploy python --image=python:3.9 -- sleep 365d



# python pod 확인
$ kubectl -n kafka get pod
NAME                                         READY   STATUS    RESTARTS       AGE
...
python-fb57f7bd4-4w6pz                       1/1     Running   0              32s
...



# python pod 내 진입(bash 실행)
$ kubectl -n kafka exec -it deploy/python -- bash

```



#### python library install

kafka 에 접근하기 위해서 kafka-python 을 설치해야 한다.

```bash
$ pip install kafka-python

Collecting kafka-python
  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 246.5/246.5 KB 3.9 MB/s eta 0:00:00
Installing collected packages: kafka-python
Successfully installed kafka-python-2.0.2
```



#### kafka host 확인

```sh
## internal 접근을 위한 host
bootstrap : my-cluster-kafka-bootstrap.kafka.svc:9092
broker0   : my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9092
broker2   : my-cluster-kafka-2.my-cluster-kafka-brokers.kafka.svc:9092
broker1   : my-cluster-kafka-1.my-cluster-kafka-brokers.kafka.svc:9092 

```





### (2) consumer

consumer 실행을 위해서 python cli 환경으로 들어가자.

```sh
$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

```



CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaConsumer

# 개인환경으로 변경
bootstrap_servers='my-cluster-kafka-bootstrap.kafka.svc:9092'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,    # 개인별 password 로 변경하자.
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id='my-topic-group')



# my-user로 확인가능한 topic 목록들을 확인할 수 있다.
consumer.topics()

# 사용할 topic 지정(구독)
consumer.subscribe("my-topic")

# 구독 확인
consumer.subscription()
#{'my-topic'}            <-- 해당 Topic 이 출력되어야 한다.



# 메세지 읽기
for message in consumer:
   print("topic=%s partition=%d offset=%d: key=%s value=%s" %
        (message.topic,
          message.partition,
          message.offset,
          message.key,
          message.value))

# 수신대기중....


'''
topic=my-topic partition=0 offset=38: key=None value=b'{"eventName":"a","num":88,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=39: key=None value=b'{"eventName":"a","num":90,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=40: key=None value=b'{"eventName":"a","num":96,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
'''
```







### (3) producer

producer 실행을 위해서 별도의 terminal 을 실행한 후 python cli 환경으로 들어가자.

```sh
# python pod 내 진입(bash 실행)
$ kubectl -n kafka exec -it deploy/python -- bash


$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

```





internal 에서 접근시에는 인증서가 없는  9092 port 접근이므로 사용되는 protocol은 SASL_PLAINTEXT 이다.CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaProducer
from time import sleep

# 개인환경으로 변경
bootstrap_servers='my-cluster-kafka-bootstrap.kafka.svc:9092'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

producer = KafkaProducer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',

# 아래 명령 부터 Consumer 수신을 관찰하면서 수행하자.
producer.send('my-topic', b'python test1')
producer.send('my-topic', b'python test2')
producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % 1)

# 10000건을 1초에 한번씩 발송해보자.
for i in range(10000):
    print(i)
    sleep(1)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

# 테스트를 끝내려면 Ctrl + C 로 중지하자.
```



- 대량 발송(성능테스트)

```python
# 만건 테스트
import time
start_time = time.time() # 시작시간
for i in range(10000):
    print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)


end_time = time.time() # 종료시간
print("duration time :", end_time - start_time)  # 현재시각 - 시작시간 = 실행 시간
# duration time : 11.0137197971344

```



- 참고

```python
# 2만건 테스트
for i in range(10001, 20000):
    print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)
    
```



- python 종료시 : Ctrl+D 





## 5.2 External Access



### (1) 준비

#### External access 를 위한 docker python 실행

```sh
## docker 실행
$ docker run --name python --user root --rm -d python:3.9 sleep 365d

# python 확인
$ docker ps -a
CONTAINER ID   IMAGE                             COMMAND                  CREATED          STATUS          PORTS     NAMES
a225dc4c3dd7   python:3.9                        "sleep 365d"             4 weeks ago      Up 20 seconds             python


# Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#

```



#### python library install

python 을 이용해서 kafka 에 접근하기 위해서는 kafka 가아닌 kafka-python 을 설치해야 한다.

```bash
$ pip install kafka-python
```



#### kafka host 확인

```sh
## external 접근을 위한 host (nodeport 기준)
bootstrap  : my-cluster.kafka.localhost.192.168.31.1.nip.io:32100
broker0    : my-cluster.kafka.localhost.192.168.31.1.nip.io:32000
broker1    : my-cluster.kafka.localhost.192.168.31.1.nip.io:32001
broker2    : my-cluster.kafka.localhost.192.168.31.1.nip.io:32002
```





### (3) consumer

consumer 실행을 위해서 python cli 환경으로 들어가자.

```sh
$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

```



CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaConsumer

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        ssl_check_hostname=True,
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id='my-topic-group')

# my-user로 확인가능한 topic 목록들을 확인할 수 있다.
consumer.topics()

# 사용할 topic 지정(구독)
consumer.subscribe("my-topic")

# 구독 확인
consumer.subscription()
#{'my-topic'}            <-- 해당 Topic 이 출력되어야 한다.


# 메세지 읽기
for message in consumer:
   print("topic=%s partition=%d offset=%d: key=%s value=%s" %
        (message.topic,
          message.partition,
          message.offset,
          message.key,
          message.value))

# 수신대기중....

'''
---
topic=my-topic partition=0 offset=38: key=None value=b'{"eventName":"a","num":88,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=39: key=None value=b'{"eventName":"a","num":90,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=40: key=None value=b'{"eventName":"a","num":96,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
'''
```







### (2) producer

producer 실행을 위해서 별도의 terminal 을 실행한 후 python cli 환경으로 들어가자.

```sh
# Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#


$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

```







CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaProducer
from time import sleep

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

producer = KafkaProducer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        ssl_check_hostname=True,
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password)

# 아래 명령 부터 Consumer 수신을 관찰하면서 수행하자.
producer.send('my-topic', b'python test1')
producer.send('my-topic', b'python test2')
producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % 1)

# 10000건을 1초에 한번씩 발송해보자.
for i in range(10000):
    print(i)
    sleep(1)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

# 테스트를 끝내려면 Ctrl + C 로 중지하자.

```



- 대량 발송(성능테스트)

```python
# 만건 테스트
import time
start_time = time.time() # 시작시간
for i in range(10000):
    print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

duration time : 8.865852355957031

```

- 결론
  - 일반적으로 External 이 Internal 보다 network 부하가 심해서 속도가 훨씬 느리다.
  - 하지만 우리가 테스트한 환경은 동일 PC 에서 실행하므로 속도가 거의 동일한 점을 참고하자.



- 참고

```python
# 2만건 테스트
for i in range(10001, 20000):
    print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)
    
```



- python 종료시 : Ctrl+D 







## 5.3 External Access(Route)



### (0) Kafka connect info

```sh
server: 
bootstrap.kafka.apps.211-34-231-82.nip.io:443
broker-0.kafka.apps.211-34-231-82.nip.io:443
broker-1.kafka.apps.211-34-231-82.nip.io:443
broker-3.kafka.apps.211-34-231-82.nip.io:443

topic : my-topic
user : my-user
pass : KV9tDU0AY4Wu

org.apache.kafka.common.security.scram.ScramLoginModule required username="my-user" password="KV9tDU0AY4Wu";

```

* ca.crt

```
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUQ+S6Q/I1Bbbgdkja3rdYpacOyOAwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA2MjUxMzUwMjlaFw0yMzA2MjUxMzUwMjlaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQCtWWBKQNMWXp7C3gyVnYG28qafYenI8wF747OEgE5x
bShImZszJKsKBQbHQgUPtWMNbHTejpLrkIqS8/dcJMI61flpTyqDZYYTKWUOdEVH
x0+hgsmcXd6pLCAdbEZ5vCSbOhEiGVuPFovq/pJGfOlFxpkSafhfWdJJ4EbwaJ7B
soXxEfsvorak2TRutNEf52syStIfa8Jy42tbWVBS3viwwybvNUA3/vbqRxehJmzJ
74oIRIumT0Qmgomte4gpn8rZGkd+pXrhRJ2v4nd5Ch9QAxUcBoBY9QbecG2/+RE3
670cmVaF2r/BPgnpUt0iYOp44iJrsNo4SDR/XU27N0AHpK0DOVbLXK1ANet22JKj
U5P0N92vLvJAUkevT7k2V7VSnBrU47TH57z260R4o1nO2mIunDpyZ7z4VQN/uPe6
ISk1ldLmmNOkJ3E1rBSwsRIXJ8dyc0IOTLIuGF6XP/PCymTWzhKrOzaTmMRxtWes
GwNTikzzxXzSM4iO6inemyGGtQi6/f5oc37O1YCFGsBTFvhAVzdcPcbFoJ6jdULm
IWBv+GZsY6Hb6YsZQPZpz3HyTL4ArW5RRTjDbFKOPIR1FbxcnQQu3zxug1WQRc7U
bRBp9YSaMVnjV9bK+ScMTx+hY1SkIPX2tuPbElh2UXpDhJDMEmYJU2VKXk0n7At1
SwIDAQABo0UwQzAdBgNVHQ4EFgQUI9x2JoR/ajwKVxR4ba6KOR7DbvQwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AB6dnPQxtvhq/vfLjcMkET13GekbmpeOgBP32ke+n3xRW3/p3ORJdXXj+QZApKPj
eKjRQmSwFfO1/2dWsUNqOx8+g4mugKMzVE/eJY6EkDmZwRaq9aYNBdsx39eaDSBB
le0Sr0kXS2NU7n60v7v1yMr3od6IPNMwoBHi0BtqcX5bGFixjPtafbWKhDovWmLC
7P3lFtsQ6yLMyVj/e6lhpO0rAcwTNTnf2zZ1/qzQKwIoCUr7XSismpRBjWxPa/wi
sTjUqWylVQlWVZVdXpWUW+Rz2gUPlKO9fzx0PtothuJsXPg7JIEI20jSzu3aASjR
UdlhDtR9U/0ASkjmgiYxkBNBJANro72muVKVCgdZg1GB9m269iQmTwm1ATIxnIbu
IJUCcumDwBq239NC2d1DUfwhFB9YMg62mSzCIZTi/ZeNPZl0Z/vGSQ4PMZbKivF7
UkHS61RyNfNE1Ryp0ekczBqlP/lfwFQgMdTEHwtuVkx4ACzyg/x2Zqt0egTpkhea
seErJA/woM8XouwgBJKpSdOyEcAQNP2o7F2hKvDiy3e0N6tbHUJ8sWCbBxSEP+yl
ikkaEPRxXKjSibe/HfYkLEBfjBeFfSmmTXApOR/+ZJeTIPtZgnRDKwxAkXiJo5r/
wmzsXFUgChPN9wnJYUQzhW+lwWaJc5ZXJmtzNokAH6fx
-----END CERTIFICATE-----
```





### (1) 준비

#### External access 를 위한 container python 실행

```
## podman 실행
$ podman run --name python --user root --rm -d python:3.9 sleep 365d

# python 확인
$ podman ps -a
CONTAINER ID   IMAGE                             COMMAND                  CREATED          STATUS          PORTS     NAMES
a225dc4c3dd7   python:3.9                        "sleep 365d"             4 weeks ago      Up 20 seconds             python


# Container 내부로 진입( bash 명령 수행)
$ podman exec -it python bash
root@a225dc4c3dd7:/#
```

#### python library install

python 을 이용해서 kafka 에 접근하기 위해서는 kafka 가아닌 kafka-python 을 설치해야 한다.

```
$ pip install kafka-python
```

#### kafka host 확인

```
## external 접근을 위한 host
bootstrap : bootstrap.kafka.apps.211-34-231-82.nip.io:443
broker0   : broker-0.kafka.apps.211-34-231-82.nip.io:443
broker1   : broker-1.kafka.apps.211-34-231-82.nip.io:443
broker2   : broker-3.kafka.apps.211-34-231-82.nip.io:443
```

### (2) consumer

consumer 실행을 위해서 python cli 환경으로 들어가자.

```
$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

CLI 환경에서 아래 Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaConsumer

# 개인환경으로 변경
# 
# topic : my-topic
# user : my-user
# pass : KV9tDU0AY4Wu
# security_protocol
#   --> PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL. Default: PLAINTEXT.
# max_poll_records=500
# max_poll_interval_ms=300000

bootstrap_servers='bootstrap.kafka.apps.211-34-231-82.nip.io:443'
sasl_user='my-user'
sasl_password='KV9tDU0AY4Wu'

consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_SSL",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username=sasl_user,
                        sasl_plain_password=sasl_password,
                        ssl_check_hostname=True,
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id='my-topic-group',
                        ssl_cafile='./ca.crt')

# 추가 옵션
consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_SSL",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username=sasl_user,
                        sasl_plain_password=sasl_password,
                        ssl_check_hostname=True,
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id='my-topic-group',
                        ssl_cafile='./ca.crt',
                        max_poll_records=500,
                        max_poll_interval_ms=300000)


# my-user로 확인가능한 topic 목록들을 확인할 수 있다.
consumer.topics()

# 사용할 topic 지정(구독)
consumer.subscribe("my-topic")

# 구독 확인
consumer.subscription()
#{'my-topic'}            <-- 해당 Topic 이 출력되어야 한다.


# 메세지 읽기
for message in consumer:
   print("topic=%s partition=%d offset=%d: key=%s value=%s" %
        (message.topic,
          message.partition,
          message.offset,
          message.key,
          message.value))

# 수신대기중....

'''
---
topic=my-topic partition=0 offset=38: key=None value=b'{"eventName":"a","num":88,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=39: key=None value=b'{"eventName":"a","num":90,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=40: key=None value=b'{"eventName":"a","num":96,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
'''
```

### (3) producer

producer 실행을 위해서 별도의 terminal 을 실행한 후 python cli 환경으로 들어가자.

```sh
# Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#


$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

CLI 환경에서 아래 Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaProducer
from time import sleep

bootstrap_servers='bootstrap.kafka.apps.211-34-231-82.nip.io:443'
sasl_user='my-user'
sasl_password='KV9tDU0AY4Wu'

producer = KafkaProducer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_SSL",
                        sasl_mechanism='SCRAM-SHA-512',
                        ssl_check_hostname=True,
                        sasl_plain_username=sasl_user,
                        sasl_plain_password=sasl_password,
                        ssl_cafile='./ca.crt')

# 아래 명령 부터 Consumer 수신을 관찰하면서 수행하자.
producer.send('my-topic', b'python test1')
producer.send('my-topic', b'python test2')
producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % 1)

# 10000건을 1초에 한번씩 발송해보자.
for i in range(1000):
    print(i)
    sleep(1)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

# 테스트를 끝내려면 Ctrl + C 로 중지하자.
```

- 대량 발송(성능테스트)

```python
# 만건 테스트
import time
start_time = time.time() # 시작시간
for i in range(10000):
    print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

duration time : 8.865852355957031
```

- 결론
  - 일반적으로 External 이 Internal 보다 network 부하가 심해서 속도가 훨씬 느리다.
  - 하지만 우리가 테스트한 환경은 동일 PC 에서 실행하므로 속도가 거의 동일한 점을 참고하자.
- 참고

```python
# 2만건 테스트
for i in range(10001, 20000):
    print(i)
    producer.send('my-topic', b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)
    
```

- python 종료시 : Ctrl+D





## 5.4 [참고] Python Admin 

### (1) Consumer Group List 

```python
from kafka.admin import KafkaAdminClient

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers, 
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        #client_id='test1'
                        )

list_cg = admin_client.list_consumer_groups()
print(type(list_cg))
print(list_cg )
# [('my-topic-group', 'consumer')]

```



### (2) describe_consumer_groups

CG 명을 던져서 topicname, partition, current-offset 이 리턴되어야 한다.

참조: https://kafka-python.readthedocs.io/en/master/apidoc/KafkaAdminClient.html

참조: https://github.com/dpkp/kafka-python/issues/1798

```python
from kafka.admin import KafkaAdminClient

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='PkcAIUblNHFg'             ## 개인별 passwrod 붙여넣자.   위 3.2 KafkaUser 를 참고하자. 

admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers, 
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        #client_id='test1'
                        )

# 그룹명을 인수로 보낼때는 반드시 리스트[] 로 보내야 한다.
cg_desc = admin_client.describe_consumer_groups(['my-topic-group'])
print(type(cg_desc))
print(cg_desc)

'''
[
GroupInformation(
error_code=0, 
group='my-topic-group', 
state='Stable', 
protocol_type='consumer', 
protocol='range', 
members=[MemberInformation(member_id='kafka-python-2.0.2-06e95b4b-6f67-467d-ac8e-64c34710c5a2', 
client_id='kafka-python-2.0.2', 
client_host='/192.168.65.3', 
member_metadata=ConsumerProtocolMemberMetadata(version=0, subscription=['my-topic'], user_data=b''), 
member_assignment=ConsumerProtocolMemberAssignment(version=0, 
assignment=[(topic='my-topic', partitions=[0, 1, 2])], 
user_data=b''))], 
authorized_operations=None)
]
'''



# offset 정보
cg_offsets = admin_client.list_consumer_group_offsets('my-topic-group')
print(type(cg_offsets))
print(cg_offsets)

'''
{
TopicPartition(topic='my-topic', partition=0): OffsetAndMetadata(offset=13449, metadata=''), 
TopicPartition(topic='my-topic', partition=1): OffsetAndMetadata(offset=13534, metadata=''), 
TopicPartition(topic='my-topic', partition=2): OffsetAndMetadata(offset=13151, metadata='')
}
'''

```



### (3) kafka admin Client

- topic 생성시

```python
from kafka.admin import KafkaAdminClient, NewTopic

# 개인환경으로 변경
bootstrap_servers='my-cluster.kafka.localhost.192.168.31.1.nip.io:32100'
sasl_plain_password='eGVNg7ZvPbi0'

admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers, 
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        #client_id='test1'
                        )

topic_list = []
topic_list.append(NewTopic(name="example_topic", num_partitions=1, replication_factor=1))
admin_client.create_topics(new_topics=topic_list, validate_only=False)

'''
---
python kafkaAdminClient.py
---
'''
```







# 6. Strimzi Clean up

WSL 에서의 Strimzi 실습이 완료되었다. 불필요한 리소스 사용을 없애기 위해서 깨끗히 삭제하도록 하자.



## 6.1 Strimzi All Clean Up

```sh

# 1) client tool clean up
kubectl -n kafka delete deploy kafkacat
kubectl -n kafka delete deploy python

# 2) kafka resource clean up
kubectl -n kafka delete kafkauser my-user
kubectl -n kafka delete kafkatopic my-topic
kubectl -n kafka delete kafka my-cluster


# 3) trimzi clean up
cd ~/githubrepo/ktds-edu2
kubectl -n kafka delete -f ./kafka/strimzi/install/cluster-operator

# 4) kafka namespace clean up
kubectl delete namespace kafka

```





## 6.2 Docker Desktop 일시정지

Kubernetes 를 포함한 docker Desktop 은 CPU 나 메모리를 많이 차지 한다. 그러므로 사용하지 않을때는 pause 해 놓자.

- 메뉴 : 우측 docker Desktop 아이콘 클릭 > Puase 클릭

![image-20220703012023558](2.kafka-hands-in.assets/image-20220703012023558.png)

 





# 7.  Java - STS

Java 실습은 Spring Boot (STS) 를 이용해서 진행할 것이다.  

KT Cloud 에 Kafka 와 관련 모니터링 툴(Prometheus, Grafana)이 설치 되어 있으며  이 환경에 접속하여 실습을 진행할 것이다.



 

## 7.1 사전정보 확인



### (1) 개인당 Topic 정보

 실습을 위해서 Topic/Group/User 정보 대해서 아래와 같이 준비되어 있다.

```sh
# topic
edu-topic-01 ~ edu-topic-30
 
# group - 사용자가 consum 할때 선언함
edu-group-01 ~ edu-group-30
 
# user는 공용
my-user
```

 

#### 접속권한

교육을 위해 한시적으로 접속권한 생성함

| **User** | **Pass**     | **비고**                            |
| -------- | ------------ | ----------------------------------- |
| my-user  | KykkJNJTcTJB | 2022년 7월까지만  유지되고 삭제예정 |



#### 개인별로 할당된 Topic 확인

| **Topic**    | **Group**    | **담당자** | **비고** |
| ------------ | ------------ | ---------- | -------- |
| edu-topic-01 | edu-group-01 | 송양종     |          |
| edu-topic-02 | edu-group-02 | 송양종     |          |
| edu-topic-03 | edu-group-03 | 송양종     |          |
| edu-topic-04 | edu-group-04 | 홍길동     |          |
| edu-topic-05 | edu-group-05 | 이순신     |          |
| edu-topic-06 | edu-group-06 |      |          |
| edu-topic-07 | edu-group-07 |      |          |
| edu-topic-08 | edu-group-08 |      |          |
| edu-topic-09 | edu-group-09 |      |          |
| edu-topic-10 | edu-group-10 |      |          |
| edu-topic-11 | edu-group-11 |      |          |
| edu-topic-12 | edu-group-12 |      |          |
| edu-topic-13 | edu-group-13 |      |          |
| edu-topic-14 | edu-group-14 |      |          |
| edu-topic-15 | edu-group-15 |      |          |
| edu-topic-16 | edu-group-16 |      |          |
| edu-topic-17 | edu-group-17 |      |          |
| edu-topic-18 | edu-group-18 |      |          |
| edu-topic-19 | edu-group-19 |      |          |
| edu-topic-20 | edu-group-20 |      |          |
| edu-topic-21 | edu-group-21 |      |          |
| edu-topic-22 | edu-group-22 |      |          |
| edu-topic-23 | edu-group-23 |      |          |
| edu-topic-24 | edu-group-24 |      |          |
| edu-topic-25 | edu-group-25 |      |          |
| edu-topic-26 | edu-group-26 |      |          |
| edu-topic-27 | edu-group-27 |       |          |
| edu-topic-28 | edu-group-28 |       |          |
| edu-topic-29 | edu-group-29 |       |          |
| edu-topic-30 | edu-group-30 |       |          |





### (2) Spring Cloud Stream

java 에서 Kafka 를 사용하는 방법에는 kafkatemplate 을 이용하는 방법 등 여러가지가 있지만 본 실습에서는 Spring Cloud Stream 를 이용할 것이다.

- Spring Cloud Stream 특징

  - 어떤 메시지 플랫폼을 사용하는지 상관없이 추상화해서기능을 제공

  - 메시지 플랫폼으로 Rabbit MQ 나 Kafka 를 사용한다고 하더라도 비즈니스 로직을 별도로 구분할 필요 없음

  - Spring 에서 Configuration 설정을 알아서 설정함

  - 매우 심플한 사용





## 7.2 kafka-consumer

PC 에 설치되어 있는 STS 를 실행하자.



### (1) sample import



- Github 의 kafka-consumer repo 주소 확인

```
https://github.com/ssongman/kafka-consumer.git
```

복사하여 클립보드에 기억한다.



- STS 에서 import 
  - Package Explorer 에서 우클릭 이후 아래 메뉴 선택


```
1) import - git - Project from Git(with smart import)

2) Select Repository Source
   Clone 선택

3) Source Git Repository
   URI 에 위 주소 붙여넣기
   클립보드에 기억된 git 주소로 자동 셋팅된다.

4) Branch Selection
   main 선택

5) local Destination 에서 프로젝트 위치 지정

6) Import Projects
   Maven 확인 후 finish
```





### (2) 소스내 Topic/Group 수정

- application-local.yaml 에서 아래 내용 수정

```yaml
spring:
  cloud:
    stream:
      function:
        definition: boardCreate
      kafka:
        binder:
          autoCreateTopics: false
          brokers:
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32100
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32000
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32001
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32002
          configuration:
            security:
              protocol: SASL_PLAINTEXT
            sasl:
              mechanism: SCRAM-SHA-512
              jaas:
                config: org.apache.kafka.common.security.scram.ScramLoginModule required username="my-user" password="KykkJNJTcTJB";
      bindings:
        boardCreate-in-0:
          destination: edu-topic-01     # 본인의 토픽명으로 수정할것
          group: edu-group-01           # 본인의 그룹명으로 수정할것
```

 

### (3) Consumer 실행

```
[Package Explorer] 
- kafka-consumer 에서 우측버튼 클릭
- Run As 
- Spring Boot App 실행
```



- Console log 확인

```
...
edu-topic-group: partitions assigned: [edu-topic-01-2, edu-topic-01-1, edu-topic-01-0]
```

- 3개의 partition 이 모두 하나의 Consumer 에 assigned 되었다.
- 차후 리발린싱 테스트시 어떻게 변경되는지 확인해 볼 것이다.



## 7.3 kafka-producer

 

### (1) sample import

- Github 의 kafka-producer repo 주소 확인

```
https://github.com/ssongman/kafka-producer.git
```

복사하여 클립보드에 기억한다.



- STS 에서 import
  - Package Explorer 에서 우클릭 이후 아래 메뉴 선택

```
1) import - git - Project from Git(with smart import)

2) Select Repository Source
   Clone 선택

3) Source Git Repository
   URI 에 위 주소 붙여넣기
   클립보드에 기억된 git 주소로 자동 셋팅된다.

4) Branch Selection
   main 선택

5) local Destination 에서 프로젝트 위치 지정

6) Import Projects
   Maven 확인 후 finish

```



### (2) 소스내 Topic 수정

src/main/resources/config/application-local.yaml 에서 아래 내용 수정

```yaml
spring: 
  cloud:
    stream:
      kafka:
        binder:
          brokers:
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32100
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32000
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32001
          - my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32002
          configuration:
            security:
              protocol: SASL_PLAINTEXT
            sasl:
              mechanism: SCRAM-SHA-512
              jaas:
                config: org.apache.kafka.common.security.scram.ScramLoginModule required username="my-user" password="KykkJNJTcTJB";
      bindings:
        boardCreate-out-0:
          destination: edu-topic-01   # 본인의 토픽명으로 수정할것
```

 

### (3) producer 실행

```
[Package Explorer] 
- kafka-producer 에서 우측버튼 클릭
- Run As 
- Spring Boot App 실행
```

 



- Console log 확인

```
...
Tomcat started on port(s): 8081 (http) with context path ''
```

- 



### (4) pub test (create api call)

postman 이나 curl 을 통해서 아래와 같이 테스트를 수행한다.

WSL 이 아닌  Local Terminal(window command, gitbash, mobaxterm shell) 에서 수행해야 함을 유의하자.

```sh
$ curl -X POST http://localhost:8081/create \
  -H "Content-Type: application/json" \
  -d '{  
  "eventName": "boardCreate",
  "num": 2,
  "title": "test insert-1",
  "contents": "test insert-1",
  "writeId": "user1",
  "writeName": "user1",
  "writeDate": "2022-07-03T01:03:00"
}'
 

## 초당 1회 call 발생(producer )
$ while true; do curl -X POST http://localhost:8081/create \
  -H "Content-Type: application/json" \
  -d '{  
  "eventName": "boardCreate",
  "num": 2,
  "title": "test insert-1",
  "contents": "test insert-1",
  "writeId": "user1",
  "writeName": "user1",
  "writeDate": "2022-07-03T01:03:00"
}'; sleep 1; echo; done


```



### (5) Grafna monitoring 확인

- URL : http://grafana.kafka.ktcloud.211.254.212.105.nip.io
- User/Pass : admin / \****
- 메뉴 위치 : Dashboards > Manage > Strimzi Kafka Exporter

![image-20220626111254872](2.kafka-hands-in.assets/image-20220626111254872.png)



- 모니터링 설치 가이드는 아래 링크 참고
  - [모니터링 설치 가이드 문서 보기](../ktcloud-setup/ktcloud-setup.md)   > Strimzi 7.Monitoring 참고






# 8. Rebalancing Round

 일반적으로 Consumer group의 멤버 구성에 변화가 생기면 리소스의 재분배가 필요한데 이를 **Rebalancing Round** 라고 한다.

이 RR 이 발생하는 동안은 어떤 컨슈머들도 정상적인 데이터 처리를 하지 못한다는 문제를 가지는데 카프카에서는 이를 **Stop The World** 라는 용어로 부른다. 

이는 수천 개의 Connect Task 가 그룹에 존재했을 때 그 수천 개의 프로세스가 전부 정상 동작하지 못하게 되는 상황을 맞이한다. 

이런 Rebalancing 과 관련된 Stop The World 는 일반적인 하드웨어나 네트워크 손실 문제로 발생한 일시적인 client fail 과 더불어, scale up / down 의 상황이나 계획적인 클라이언트 start / stop / restart 의 상황에서 전부 발생할 수 있다. 

그럼 Consumer 갯수에 따른 Partition 매핑 관계와 Consumer Rebalancing 현상에 대해서 확인해 보자.



## 8.1 Rebalancing 시나리오

### (1) 설명 

- Partition 3개인 Topic 에서 Consumer 갯수 변화에 따른 partition assigned 현황 관찰

### (2) Consumer 환경 

- Consumer1:  Spring boot

- Consumer2:  python [docker container]
- Consumer3:  python [docker container]
- Consumer4:  python [docker container]

### (3) Producer 환경 

- 한개의 python producer 에서 1초에 한번씩 전송





## 8.2 테스트 수행 

아래 `8.3 python test 수행`을 참고하여 테스트 수행한다.



### (1) step1 :  Spring boot  - Consumer

- edu-topic-01 / edu-group-01 셋팅후 실행

- Spring boot 로 Consumer 실행한다.

- Spring boot log 를 확인한다.

- 예상결과 : partition 1,2,3 이 모두 한꺼번에 assigned 될 것이다.

  ```
  edu-group-01: partitions assigned: [edu-topic-01-2, edu-topic-01-1, edu-topic-01-0]
  ```

  

### (2) step2 :  python  - Consumer 1 실행

- python  로 Consumer 실행한다.

- Spring boot log 를 확인한다.

- 예상결과 : partition 1,2,3 중 하나가 제외 처리 될 것이다.

  ```
  edu-group-01: partitions assigned: [edu-topic-01-2, edu-topic-01-1]
  ```

  

### (3) step3 :  python  - Consumer2 실행

- python  로 Consumer 실행한다.

- Spring boot log 를 확인한다.

- 예상결과 : partition 1,2,3 중 두개가 제외 처리 될 것이다.

  ```
  edu-group-01: partitions assigned: [edu-topic-01-2]
  ```



### (4) step4 :  python  - Consumer3 실행

- python  로 Consumer 실행한다.
- Spring boot log 를 확인한다.
- 예상결과 : 변화사항이 없다. - assigned 될 partition 이 없어서 Consumer 가 낭비되는 상황이다.



### (5) step5 :  python  - producer 실행

- python producer 로 초당 1회 발송
- Grafana 확인
- 각각 Consumer log 를 확인한다.
- 예상결과
  - 3개의 Consumer 에서 각각 로그가 균등하게 출력될 것이다. 
  - assigned 되지 못한 python-consumer3 은 변화가 없을 것이다.



### (6) step6 :  python  - Consumer 삭제

- producer 초당 1회 발송을 유지하며 ...
- python Consumer 3번을 제거한다.
- [stop the world확인] 각각 Consumer log 를 확인한다. 
- python Consumer 2번을 제거
- [stop the world확인] 각각 Consumer log 를 확인한다. 
- python Consumer 1번을 제거
- [stop the world확인] 각각 Consumer log 를 확인한다. 

 

### (7) step7: Clean up







## 8.3 python test 환경

docker python 을 이용해서 테스트 를 수행한다.



### (1) KT Cloud kafka host 확인

```sh
## external 접근을 위한 host (nodeport 기준)
bootstrap  : my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32100
broker0    : my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32000
broker1    : my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32001
broker2    : my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32002

## 인증정보
my-user / pprOnk80CDfo
```





### (2) consumer

consumer 실행을 위해서 python cli 환경으로 들어가자.

```sh
# Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash
root@a225dc4c3dd7:/#


$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

```



CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaConsumer

# KT Cloud 환경으로 변경
bootstrap_servers='my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32100'
sasl_plain_password='KykkJNJTcTJB'
topic_name='edu-topic-01'
group_id='edu-group-01'

consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password,
                        ssl_check_hostname=True,
                        auto_offset_reset='earliest',
                        enable_auto_commit= True,
                        group_id=group_id)

# my-user로 확인가능한 topic 목록들을 확인할 수 있다.
consumer.topics()

# 사용할 topic 지정(구독)
consumer.subscribe(topic_name)

# 구독 확인
consumer.subscription()
#                       <-- 해당 Topic 이 출력되어야 한다.


# 메세지 읽기
for message in consumer:
   print("topic=%s partition=%d offset=%d: key=%s value=%s" %
        (message.topic,
          message.partition,
          message.offset,
          message.key,
          message.value))

# 수신대기중....

'''
---
topic=my-topic partition=0 offset=38: key=None value=b'{"eventName":"a","num":88,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=39: key=None value=b'{"eventName":"a","num":90,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
topic=my-topic partition=0 offset=40: key=None value=b'{"eventName":"a","num":96,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }'
'''
```







### (3) producer

producer 실행을 위해서 별도의 terminal 을 실행한 후 python cli 환경으로 들어가자.

```sh
# Container 내부로 진입( bash 명령 수행)
$ docker exec -it python bash

root@a225dc4c3dd7:/#


$ python

Python 3.9.13 (main, May 28 2022, 13:56:03)
[GCC 10.2.1 20210110] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

```







CLI 환경에서 아래  Python 명령을 하나씩 실행해 보자.

```python
from kafka import KafkaProducer
from time import sleep

# KT Cloud 환경으로 변경
bootstrap_servers='my-cluster.kafka.ktcloud.211.254.212.105.nip.io:32100'
sasl_plain_password='KykkJNJTcTJB'
topic_name='edu-topic-01'

producer = KafkaProducer(bootstrap_servers=bootstrap_servers,
                        security_protocol="SASL_PLAINTEXT",
                        sasl_mechanism='SCRAM-SHA-512',
                        ssl_check_hostname=True,
                        sasl_plain_username='my-user',
                        sasl_plain_password=sasl_plain_password)

# 아래 명령 부터 Consumer 수신을 관찰하면서 수행하자.
producer.send(topic_name, b'python test1')
producer.send(topic_name, b'python test2')
producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % 1)

# 10000건을 0.5초에 한번씩 발송해보자.
for i in range(10000):
    print(i)
    sleep(0.5)
    producer.send(topic_name, b'{"eventName":"a","num":%d,"title":"a", "writeId":"", "writeName": "", "writeDate":"" }' % i)

# 테스트를 끝내려면 Ctrl + C 로 중지하자.

```



## 8.4 Trouble Shooting

### (1)  현상

Rebalancing 이 반복해서 발생하면서 처리가 멈춘다.



### (2) 분석 - Rebalancing 발생하는 현상

Consumer 가 추가 되는 경우 말고도 아래와 같은 경우가 발생할 수 있다.

* session.timeout.ms 설정시간에 heartbeat 시그널을 받지 못해 리밸런스가 발생하는 경우

* max.poll.interval.ms 설정시간에 poll() 메소드가 호출되지 않아 리밸런스가 발생하는 경우



| 옵션명                    | 설명                                                         | 기본값       |
| :------------------------ | :----------------------------------------------------------- | :----------- |
| `session.timeout.ms`      | 컨슈머와 브로커사이의 session timeout 시간. 컨슈머가 살아있는것으로 판단하는 시간으로 **이 시간이 지나면 해당 컨슈머는 종료되거나 장애가 발생한것으로 판단하고 컨슈머 그룹은 리밸런스를 시도한다.** 이 옵션은 heartbeat 없이 얼마나 오랫동안 컨슈머가 있을 수 있는지를 제어하며 heartbeat.interval.ms와 밀접한 관련이 있어서 일반적으로 두 속성이 함께 수정된다. | 10000 (10초) |
| `heartbeat.interval.ms`   | 컨슈머가 얼마나 자주 heartbeat을 보낼지 조정한다. session.timeout.ms보다 작아야 하며 일반적으로 1/3로 설정 | 3000 (3초)   |
| `max.poll.interval.ms`    | 컨슈머가 polling하고 commit 할때까지의 대기시간. 컨슈머가 살아있는지를 체크하기 위해 hearbeat를 주기적으로 보내는데, 계속해서 heartbeat만 보내고 실제로 메시지를 가져가지 않는 경우가 있을 수 있다. 이러한 경우에 컨슈머가 무한정 해당 파티션을 점유할 수 없도록 **주기적으로 poll을 호출하지 않으면 장애라고 판단하고 컨슈머 그룹에서 제외**시키도록 하는 옵션이다. | 300000 (5분) |
| `max.poll.records`        | 컨슈머가 최대로 가져 갈 수있는 갯수. 이 옵션으로 polling loop에서 데이터 양을 조정 할 수 있다. | 500          |
| `enable.auto.commit`      | 백그라운드로 주기적으로 offset을 commit                      | true         |
| `auto.commit.interval.ms` | 주기적으로 offset을 커밋하는 시간                            | 5000 (5초)   |
| `auto.offset.reset`       | earliest: 가장 초기의 offset값으로 설정 latest: 가장 마지막의 offset값으로 설정 none: 이전 offset값을 찾지 못하면 error 발생 | latest       |

[더 많은 컨슈머 옵션보기](https://kafka.apache.org/documentation/#consumerconfigs)





컨슈머는 메시지를 가져오기위해 브로커에 poll()요청을 보내고, 컨슈머는 가져온 메시지를 처리한 후, 해당 파티션의 offset을 커밋하게 된다.

poll요청을 보내고 다음 poll을 요청을 보내는데 까지의 시간이 max.poll.interval.ms의 기본값인 300000 (5분) 보다 늦으면 브로커는 컨슈머에 문제가 있다고 판단하여 리밸런싱을 일으키게 된다.

*max.poll.interval.ms 기본값 : 300000(5분)*
*max.poll.records 기본값 : 500*



그러므로 해결방안은 아래와 같이 두가지가 있을 수 있다.

1) 500개  처리하는데 소요되는 적정 시간을 늘린다.(ex, max.poll.interval.ms=600000 (10분))
2) 한번에 처리되는 poll 갯수를 줄인다. (ex,  max.poll.records=100 으로 조정)





max.poll.interval.ms 조정 처리 예제

```java


public class ChangeKafkaListener
{	
	@KafkaListener( topics       = "my-topic"
				  , groupId      = "my-topic-group"
				  , errorHandler = "changeKafkaListenerErrorHandler"
				  , properties   = {"max.poll.interval.ms=108000000"} ) // 300000:5분, 108000000: 30분
	public void onMessage(String msg)
	{
		...
    }
```

